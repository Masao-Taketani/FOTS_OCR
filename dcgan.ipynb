{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dcgan.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masao-Taketani/FOTS_ocr_project/blob/master/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "svr0lCa0jHVy"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Masao-Taketani/gan_practice/blob/master/dcgan.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zoJVq7aUjHV2",
        "outputId": "8646b842-0745-4bcd-d433-32a47133d5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization,\\\n",
        "Activation, Dropout, Flatten, Dense, Reshape, UpSampling2D, LeakyReLU,\\\n",
        "ZeroPadding2D\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import RandomNormal"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7t17X53-3AwY",
        "outputId": "77744157-bdab-4495-d988-4d27c342f86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_paths = []\n",
        "\n",
        "#dataset_path = \"dataset/dog_data/\"\n",
        "dataset_path = \"drive/My Drive/dataset/gan/dog_imgs/\"\n",
        "img_dirs = glob(dataset_path + \"*\")\n",
        "for di in img_dirs:\n",
        "    imgs = glob(di + \"/*\")\n",
        "    for img in imgs:\n",
        "        img_paths.append(img)\n",
        "        \n",
        "len(img_paths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20590"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZQPFivBWZUG",
        "colab_type": "code",
        "outputId": "a5b40646-0c4a-48b9-9738-09fc2d71b6fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = []\n",
        "img_size = 128\n",
        "\n",
        "for i_path in img_paths:\n",
        "    img = Image.open(i_path)\n",
        "    resized_img = img.resize((img_size, img_size))\n",
        "    np_img = np.array(resized_img, dtype=np.float32)\n",
        "    if np_img.shape != (128, 128, 3):\n",
        "        print(\"Error\")\n",
        "        print(\"path:\", i_path)\n",
        "        continue\n",
        "    np_img = np_img / 127.5 - 1.0\n",
        "    x_train.append(np_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error\n",
            "path: drive/My Drive/dataset/gan/dog_imgs/n02105855-Shetland_sheepdog/n02105855_2933.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JM9nBmZzjHWA",
        "outputId": "1028b1bf-1b56-4739-c4d3-74606234d842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20589, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i4ZDY3fjjHWD",
        "colab": {}
      },
      "source": [
        "# hyper params\n",
        "channel_size = 3\n",
        "input_dims = (img_size, img_size, channel_size)\n",
        "num_disc_layers = 4\n",
        "disc_conv_fils = [32, 64, 128, 256]\n",
        "disc_conv_kernel_size = [3, 3, 3, 3]\n",
        "disc_conv_strides = [2, 2, 2, 1]\n",
        "disc_batch_norm_momentum = 0.8\n",
        "disc_dropout_rate = 0.25\n",
        "\n",
        "z_dims = 100\n",
        "shape_after_dense = (img_size//4, img_size//4, 128)\n",
        "gen_upsamp_layers = [True, True, False]\n",
        "gen_batch_norm_momentum = 0.8\n",
        "gen_dropout_rate = None\n",
        "num_gen_layers = 3\n",
        "gen_conv_fils = [128, 64, channel_size]\n",
        "gen_conv_kernel_size = [3, 3, 3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TtNjH37UjHWG"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjVNAOwpjHWH",
        "outputId": "4f348efb-ebb7-475b-a0c9-c768cce259ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "disc_input = Input(shape=input_dims, name=\"disc_input\")\n",
        "x = disc_input\n",
        "\n",
        "for i in range(num_disc_layers):\n",
        "    x = Conv2D(filters=disc_conv_fils[i],\n",
        "              kernel_size=disc_conv_kernel_size[i],\n",
        "              strides=disc_conv_strides[i],\n",
        "              padding=\"same\",\n",
        "              name=\"disc_conv_\" + str(i)\n",
        "              )(x)\n",
        "    \n",
        "    if i == 1:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        padding: Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
        "        If int: the same symmetric padding is applied to height and width.\n",
        "        If tuple of 2 ints: interpreted as two different symmetric padding\n",
        "            values for height and width: (symmetric_height_pad, symmetric_width_pad).\n",
        "        If tuple of 2 tuples of 2 ints: interpreted \n",
        "            as ((top_pad, bottom_pad), (left_pad, right_pad))\n",
        "        \"\"\"\n",
        "        x = ZeroPadding2D(padding=((0, 1), (0, 1)))(x)\n",
        "        \n",
        "    if disc_batch_norm_momentum and i > 0:\n",
        "        x = BatchNormalization(momentum=disc_batch_norm_momentum)(x)\n",
        "        \n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    \n",
        "    if disc_dropout_rate:\n",
        "        x = Dropout(disc_dropout_rate)(x)\n",
        "    \n",
        "x = Flatten()(x)\n",
        "disc_output = Dense(1, activation=\"sigmoid\")(x)\n",
        "disc_model = Model(disc_input, disc_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4gEeKTFbjHWJ",
        "outputId": "1324ecf8-c618-424e-f906-f5fd862ab503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "disc_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "disc_input (InputLayer)      [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "disc_conv_0 (Conv2D)         (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "disc_conv_1 (Conv2D)         (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 33, 33, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 33, 33, 64)        0         \n",
            "_________________________________________________________________\n",
            "disc_conv_2 (Conv2D)         (None, 17, 17, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 17, 17, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "disc_conv_3 (Conv2D)         (None, 17, 17, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 17, 17, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 73984)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 73985     \n",
            "=================================================================\n",
            "Total params: 464,193\n",
            "Trainable params: 463,297\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uOLW7uELjHWN"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dySryfiFjHWN",
        "colab": {}
      },
      "source": [
        "gen_input = Input(shape=(z_dims,), name=\"gen_input\")\n",
        "x = gen_input\n",
        "x = Dense(np.prod(shape_after_dense))(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Reshape(shape_after_dense)(x)\n",
        "for i in range(num_gen_layers):\n",
        "    if gen_upsamp_layers[i]:\n",
        "        x = UpSampling2D()(x)\n",
        "        \n",
        "    x = Conv2D(gen_conv_fils[i],\n",
        "              gen_conv_kernel_size[i],\n",
        "              padding=\"same\",\n",
        "              name=\"gen_conv_\" + str(i)\n",
        "              )(x)\n",
        "    \n",
        "    if i < num_gen_layers - 1:\n",
        "        if gen_batch_norm_momentum:\n",
        "            x = BatchNormalization(\n",
        "            momentum=gen_batch_norm_momentum)(x)\n",
        "            \n",
        "        x = Activation(\"relu\")(x)\n",
        "    else:\n",
        "        x = Activation(\"tanh\")(x)\n",
        "        \n",
        "gen_output = x\n",
        "gen_model = Model(gen_input, gen_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yacwHHYijHWQ",
        "outputId": "5fc81b3d-a5ca-4ef7-f33b-aeb5f371b1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "gen_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gen_input (InputLayer)       [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 131072)            13238272  \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "gen_conv_0 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "gen_conv_1 (Conv2D)          (None, 128, 128, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "gen_conv_2 (Conv2D)          (None, 128, 128, 3)       1731      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 13,462,147\n",
            "Trainable params: 13,461,763\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MkWHS_GujHWS"
      },
      "source": [
        "## Train the GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HRs0OP7kjHWT"
      },
      "source": [
        "### compile discriminator train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-WH5Pr5yjHWU",
        "outputId": "9be0c6cd-7849-412c-b736-de2ef0f2b0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "disc_model.compile(#optimizer=RMSprop(lr=0.0008),\n",
        "                  optimizer=Adam(0.0002, 0.5),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "djYZgDcrjHWX",
        "outputId": "1bc33f1b-90c0-4170-8aaa-dcdc92cf27fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# freeze the discriminator model so that it only makes\n",
        "# the generator model train on this model\n",
        "disc_model.trainable = False\n",
        "comb_model_input = Input(shape=(z_dims,), name=\"comb_model_input\")\n",
        "comb_model_output = disc_model(gen_model(comb_model_input))\n",
        "comb_model = Model(comb_model_input, comb_model_output)\n",
        "comb_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "comb_model_input (InputLayer [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 128, 128, 3)       13462147  \n",
            "_________________________________________________________________\n",
            "model (Model)                (None, 1)                 464193    \n",
            "=================================================================\n",
            "Total params: 13,926,340\n",
            "Trainable params: 13,461,763\n",
            "Non-trainable params: 464,577\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9hEV9TQQjHWa"
      },
      "source": [
        "### compile generator train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OyjYq695jHWa",
        "colab": {}
      },
      "source": [
        "comb_model.compile(#optimizer=RMSprop(0.0004),\n",
        "             optimizer=Adam(0.0002, 0.5),\n",
        "             loss=\"binary_crossentropy\",\n",
        "             metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClsLux-4jHWd",
        "colab": {}
      },
      "source": [
        "def train_disc(disc_model, gen_model, x_train, batch_size):\n",
        "    # create 2-dim labels\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    fake_labels = np.zeros((batch_size, 1))\n",
        "    \n",
        "    # train on real imgs\n",
        "    # np.random.randint(min, max, size)\n",
        "    idxes = np.random.randint(0, len(x_train), batch_size)\n",
        "    real_imgs = x_train[idxes]\n",
        "    \n",
        "    disc_real_loss = disc_model.train_on_batch(real_imgs, real_labels)\n",
        "    \n",
        "    # train on fake imgs\n",
        "    # np.random.normal(mean, std, size)\n",
        "    # the blow follows the standard normal distribution\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
        "    fake_imgs = gen_model.predict(noise)\n",
        "    \n",
        "    disc_fake_loss = disc_model.train_on_batch(fake_imgs, fake_labels)\n",
        "    disc_loss = 0.5 * np.add(disc_real_loss, disc_fake_loss)\n",
        "    return disc_loss\n",
        "\n",
        "\n",
        "def train_gen(comb_model, batch_size):\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dims))\n",
        "    \n",
        "    gen_loss = comb_model.train_on_batch(noise, real_labels)\n",
        "    return gen_loss\n",
        "\n",
        "\n",
        "def plot_generated_imgs(rows, cols, noises, it, gen_model):\n",
        "    print(\"iteration: \", it)\n",
        "\n",
        "    gen_imgs = gen_model.predict(noises)\n",
        "\n",
        "    # since gen model outputs values ranging from -1 to 1,\n",
        "    # nomalize imgs ranging from 0 to 1\n",
        "    #=====================================================================\n",
        "    # matplotlib.pyplot.imshow(..., norm=None, ...):\n",
        "    # By default, a linear scaling mapping the lowest value to 0 and\n",
        "    # the highest to 1 is used. This parameter is ignored for RGB(A) data.\n",
        "    #=====================================================================\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols)\n",
        "\n",
        "    ith_img = 0\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            try:\n",
        "                axs[row, col].imshow(gen_imgs[ith_img,:,:,0], cmap=\"gray\")\n",
        "                axs[row, col].axis(\"off\")\n",
        "                ith_img += 1\n",
        "            except IndexError:\n",
        "                axs[col].imshow(gen_imgs[ith_img,:,:,0], cmap=\"gray\")\n",
        "                axs[col].axis(\"off\")\n",
        "                ith_img += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JosF9dJVjHWl",
        "outputId": "d2735beb-d48a-4a27-b43b-f81c297336be",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "iterations = 20_000\n",
        "batch_size = 32\n",
        "rows, cols = 1, 5\n",
        "noises = np.random.normal(0, 1, (rows * cols, z_dims))\n",
        "\n",
        "print(\"[training log]\")\n",
        "for it in range(iterations):\n",
        "    disc_loss = train_disc(disc_model, gen_model, x_train, batch_size)\n",
        "    gen_loss = train_gen(comb_model, batch_size)\n",
        "    \n",
        "    if it % 1000 == 0:\n",
        "        print(\"iteration: %d disc loss: %f, disc acc: %.2f%% | gen loss: %f, \"\n",
        "        \"gen acc: %.2f%%\" % \n",
        "          (it, disc_loss[0], 100 * disc_loss[1], gen_loss[0], gen_loss[1]))\n",
        "        plot_generated_imgs(rows, cols, noises, it, gen_model)\n",
        "        \n",
        "print(\"[5 generated images for each 1000th iteration]\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[training log]\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "iteration: 0 disc loss: 2.635599, disc acc: 18.75% | gen loss: 0.178372, gen acc: 0.97%\n",
            "iteration:  0\n",
            "iteration: 1000 disc loss: 0.258594, disc acc: 90.62% | gen loss: 0.564881, gen acc: 0.78%\n",
            "iteration:  1000\n",
            "iteration: 2000 disc loss: 0.553202, disc acc: 70.31% | gen loss: 0.344697, gen acc: 0.88%\n",
            "iteration:  2000\n",
            "iteration: 3000 disc loss: 1.317289, disc acc: 48.44% | gen loss: 1.257062, gen acc: 0.28%\n",
            "iteration:  3000\n",
            "iteration: 4000 disc loss: 0.515059, disc acc: 71.88% | gen loss: 1.414170, gen acc: 0.22%\n",
            "iteration:  4000\n",
            "iteration: 5000 disc loss: 0.458918, disc acc: 79.69% | gen loss: 1.047156, gen acc: 0.41%\n",
            "iteration:  5000\n",
            "iteration: 6000 disc loss: 0.300063, disc acc: 92.19% | gen loss: 0.335218, gen acc: 0.94%\n",
            "iteration:  6000\n",
            "iteration: 7000 disc loss: 0.921092, disc acc: 50.00% | gen loss: 1.342178, gen acc: 0.22%\n",
            "iteration:  7000\n",
            "iteration: 8000 disc loss: 0.863422, disc acc: 56.25% | gen loss: 1.340371, gen acc: 0.31%\n",
            "iteration:  8000\n",
            "iteration: 9000 disc loss: 0.440706, disc acc: 87.50% | gen loss: 1.258740, gen acc: 0.34%\n",
            "iteration:  9000\n",
            "iteration: 10000 disc loss: 1.157100, disc acc: 54.69% | gen loss: 1.072025, gen acc: 0.38%\n",
            "iteration:  10000\n",
            "iteration: 11000 disc loss: 0.356398, disc acc: 84.38% | gen loss: 1.510093, gen acc: 0.31%\n",
            "iteration:  11000\n",
            "iteration: 12000 disc loss: 1.023181, disc acc: 45.31% | gen loss: 2.371245, gen acc: 0.03%\n",
            "iteration:  12000\n",
            "iteration: 13000 disc loss: 0.457567, disc acc: 75.00% | gen loss: 2.860354, gen acc: 0.06%\n",
            "iteration:  13000\n",
            "iteration: 14000 disc loss: 0.424465, disc acc: 78.12% | gen loss: 1.978119, gen acc: 0.19%\n",
            "iteration:  14000\n",
            "iteration: 15000 disc loss: 0.891018, disc acc: 56.25% | gen loss: 2.843063, gen acc: 0.06%\n",
            "iteration:  15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uu5NCGJvvFvi",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}